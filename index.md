---
layout: page
title:  Machine Learning and Computer Security Workshop
---

# Overview

While traditional computer security relies on well-defined
attack models and proofs of security, a science of security
for machine learning systems has proven more elusive. This
is due to a number of obstacles, including (1) the highly
varied angles of attack against ML systems, (2) the lack of
a clearly defined attack surface (because the source of the
data analyzed by ML systems is not easily traced), and (3)
the lack of clear formal definitions of security that are
appropriate for ML systems. At the same time, security of
ML systems is of great import due the recent trend of using
ML systems as a line of defense against malicious behavior
(e.g., network intrusion, malware, and ransomware), as well
as the prevalence of ML systems as parts of sensitive and
valuable software systems (e.g. sentiment analyzers for
predicting stock prices). This workshop will bring together
experts from the computer security and machine learning
communities in an attempt to highlight recent work in this
area, as well as to clarify the foundations of secure ML and
chart out important directions for future work and
cross-community collaborations.

# Room

Shoreline room in Hyatt Hotel

# Invited Speakers

<div class="instructors">
     <div class="instructor">
       <a href="https://www.cs.purdue.edu/homes/alanqi/">
         <div class="instructorphoto"><img src="assets/people/Yuan_Qi.jpg"/></div>
         <div>Alan Qi</div>
         <div>Ant Financial</div>
       </a>
     </div>
     <div class="instructor">
       <a href="http://www.allandafoe.com/">
         <div class="instructorphoto"><img src="assets/people/dafoe.jpg"/></div>
         <div>Allan Dafoe</div>
         <div>Yale University</div>
       </a>
     </div>
     <div class="instructor">
       <a href="http://theory.stanford.edu/~barrett/">
         <div class="instructorphoto"><img src="assets/people/ClarkBarrett.jpg"/></div>
         <div>Clark Barrett</div>
         <div>Stanford University</div>
       </a>
     </div>
</div>

<div class="instructors">
     <div class="instructor">
       <a href="https://www.microsoft.com/en-us/research/people/donaldbr/">
         <div class="instructorphoto"><img src="assets/people/onstage.jpg"/></div>
         <div>Donald Brinkman</div>
         <div>Microsoft Research</div>
       </a>
     </div>
     <div class="instructor">
       <a href="https://research.google.com/pubs/105214.html">
         <div class="instructorphoto"><img src="assets/people/iangoodfellow.jpg"/></div>
         <div>Ian Goodfellow</div>
         <div>Google Brain</div>
       </a>
     </div>
     <div class="instructor">
       <a href="http://mrtz.org/">
         <div class="instructorphoto"><img src="assets/people/mhardt.jpg"/></div>
         <div>Moritz Hardt</div>
         <div>UC Berkeley</div>
       </a>
     </div>
</div>


# Contributing your talks

The [Call for Papers](cfp.md) is available.

# Schedule

9:00 - Opening Remarks

**Session 1: Secure Machine Learning in Practice**

Session Chair: Chang Liu

9:15 - Invited Talk #1: *AI Applications in Security at Ant Financial* by [Alan Qi](https://www.cs.purdue.edu/homes/alanqi/)

9:45 - Contributed Talk #1: *A Word Graph Approach for Dictionary Detection and Extraction in DGA Domain Names* by Mayana Pereira, Shaun Coleman, Martine De Cock, Bin Yu and Anderson Nascimento

10:00 - Contributed Talk #2: *Practical Machine Learning for Cloud Intrusion Detection* by Ram Shankar Siva Kumar, Andrew Wicker and Matt Swann

10:15 - Poster Spotlights #1

* *Verifying Properties of Binarized Deep Neural Networks* by Nina Narodytska

* *Cascade Adversarial Machine Learning Regularized with a Unified Embedding* by Taesik Na

* *ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models* by Huan Zhang

* *DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning* by Min Du

* *Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks* by Yanjun Qi

* *A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations* by Dimitris Tsipras

* *A Neural-Symbolic Approach to Design of CAPTCHA* by Qiuyuan Huang

10:30 - Coffee Break

**Session 2: Machine Learning, Cybersecurity, and Society**

Session Chair: Jacob Steinhardt

11:00 - Invited Talk #2: *International Security and the AI Revolution by* by [Allan Dafoe](http://www.allandafoe.com)

11:30 - Contributed Talk #3: *BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain* by Tianyu Gu, Brendan Dolan-Gavitt and Siddharth Garg

11:45 - Poster Spotlights #2

* *Interpretation of Neural Networks is Fragile* by Amirata Ghorbani 

* *Thermometer Encoding: One Hot way to resist Adversarial Examples* by Jacob Buckman 

* *Adversarial Patch* by Tom Brown

* *Distributionally Robust Deep Learning as a Generalization of Adversarial Training* by Matthew Staib

* *Certifiable Distributional Robustness with Principled Adversarial Training* Aman Sinha

* *Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation* by Matthias Hein

* *Query-limited Black-box Attacks to Classifiers* by Suya FNU

* *JPEG-resistant Adversarial Images* by Richard Shin

12:00 - Lunch

**Session 3: Security Vulnerabilities of Machine Learning Systems**

Session Chair: Nicolas Papernot

1:30 - Invited Talk #4: *Defending Against Adversarial Examples* by [Ian Goodfellow](https://research.google.com/pubs/105214.html)

2:00 - Contributed Talk #4: *Provable defenses against adversarial examples via the convex outer adversarial polytope* by	J. Zico Kolter and Eric Wong

2:15 - Invited Talk #5: *Games People Play (With Bots)* by [Donald Brinkman](https://www.microsoft.com/en-us/research/people/donaldbr/)

2:45 - Contributed Demo: *Synthesizing Robust Adversarial Examples* by	Anish Athalye, Logan Engstrom, Andrew Ilyas and Kevin Kwok

3:00 - Poster Session/Break

**Session 4: Formal Definitions and Formal Verification**

Session Chair: Bo Li

3:45 - Invited Talk #5: *Safety beyond Security: Societal Challenges for Machine Learning* by [Moritz Hardt](http://mrtz.org/)

4:15 - Invited Talk #6: *Towards Verification of Deep Neural Networks* by [Clark Barrett](http://theory.stanford.edu/~barrett/)


# Organizer


<div class="instructors">
     <div class="organizer">
       <a href="mailto:jacob.steinhardt@gmail.com">
         <div class="organizerphoto"><img src="assets/people/jacob.png"/></div>
         <div>Jacob Steinhardt</div>
       </a>
     </div>
     <div class="organizer">
       <a href="mailto:crystalboli@berkeley.edu">
         <div class="organizerphoto"><img src="assets/people/boli.jpg"/></div>
         <div>Bo Li</div>
       </a>
     </div>
     <div class="organizer">
       <a href="mailto:liuchang@eecs.berkeley.edu">
         <div class="organizerphoto1"><img src="assets/people/chang.jpg"/></div>
         <div>Chang Liu</div>
       </a>
     </div>
     <div class="organizer">
       <a href="mailto:ngp5056@cse.psu.edu">
         <div class="organizerphoto"><img src="assets/people/ngp.png"/></div>
         <div>Nicolas Papernot</div>
       </a>
     </div>
     <div class="organizer">
       <a href="mailto:pliang@stanford.edu">
         <div class="organizerphoto"><img src="assets/people/percy.jpeg"/></div>
         <div>Percy Liang</div>
       </a>
     </div>
     <div class="organizer">
       <a href="mailto:dawnsong@cs.berkeley.edu">
         <div class="organizerphoto"><img src="assets/people/dawnsong.jpg"/></div>
         <div>Dawn Song</div>
       </a>
     </div>
</div>
